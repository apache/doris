diff -uprN a/CMakeLists.txt b/CMakeLists.txt
--- a/CMakeLists.txt	2021-09-28 17:39:01.747718492 +0800
+++ b/CMakeLists.txt	2021-09-28 17:44:47.934137768 +0800
@@ -531,6 +531,6 @@ if (BUILD_EXAMPLES)
   add_subdirectory("doc/examples" examples)
 endif()
 
-if (${SWIG_FOUND} AND ${PYTHONLIBS_FOUND})
-  add_subdirectory("src/python" python)
-endif()
+#if (${SWIG_FOUND} AND ${PYTHONLIBS_FOUND})
+#  add_subdirectory("src/python" python)
+#endif()
diff -uprN a/src/s2/third_party/absl/base/internal/unaligned_access.h b/src/s2/third_party/absl/base/internal/unaligned_access.h
--- a/src/s2/third_party/absl/base/internal/unaligned_access.h	2021-09-28 17:39:01.782720861 +0800
+++ b/src/s2/third_party/absl/base/internal/unaligned_access.h	2021-09-28 17:42:50.863217996 +0800
@@ -80,7 +80,7 @@ inline uint32_t UnalignedLoad32(const vo
   return __sanitizer_unaligned_load32(p);
 }
 
-inline uint64 UnalignedLoad64(const void *p) {
+inline uint64_t UnalignedLoad64(const void *p) {
   return __sanitizer_unaligned_load64(p);
 }
 
@@ -92,7 +92,7 @@ inline void UnalignedStore32(void *p, ui
   __sanitizer_unaligned_store32(p, v);
 }
 
-inline void UnalignedStore64(void *p, uint64 v) {
+inline void UnalignedStore64(void *p, uint64_t v) {
   __sanitizer_unaligned_store64(p, v);
 }
 
@@ -130,8 +130,8 @@ inline uint32_t UnalignedLoad32(const vo
   return t;
 }
 
-inline uint64 UnalignedLoad64(const void *p) {
-  uint64 t;
+inline uint64_t UnalignedLoad64(const void *p) {
+  uint64_t t;
   memcpy(&t, p, sizeof t);
   return t;
 }
@@ -140,7 +140,7 @@ inline void UnalignedStore16(void *p, ui
 
 inline void UnalignedStore32(void *p, uint32_t v) { memcpy(p, &v, sizeof v); }
 
-inline void UnalignedStore64(void *p, uint64 v) { memcpy(p, &v, sizeof v); }
+inline void UnalignedStore64(void *p, uint64_t v) { memcpy(p, &v, sizeof v); }
 
 }  // namespace base_internal
 }  // namespace absl
@@ -172,14 +172,14 @@ inline void UnalignedStore64(void *p, ui
 #define ABSL_INTERNAL_UNALIGNED_LOAD32(_p) \
   (*reinterpret_cast<const uint32_t *>(_p))
 #define ABSL_INTERNAL_UNALIGNED_LOAD64(_p) \
-  (*reinterpret_cast<const uint64 *>(_p))
+  (*reinterpret_cast<const uint64_t *>(_p))
 
 #define ABSL_INTERNAL_UNALIGNED_STORE16(_p, _val) \
   (*reinterpret_cast<uint16_t *>(_p) = (_val))
 #define ABSL_INTERNAL_UNALIGNED_STORE32(_p, _val) \
   (*reinterpret_cast<uint32_t *>(_p) = (_val))
 #define ABSL_INTERNAL_UNALIGNED_STORE64(_p, _val) \
-  (*reinterpret_cast<uint64 *>(_p) = (_val))
+  (*reinterpret_cast<uint64_t *>(_p) = (_val))
 
 #elif defined(__arm__) && \
       !defined(__ARM_ARCH_5__) && \
@@ -246,13 +246,13 @@ struct Unaligned32Struct {
 namespace absl {
 namespace base_internal {
 
-inline uint64 UnalignedLoad64(const void *p) {
-  uint64 t;
+inline uint64_t UnalignedLoad64(const void *p) {
+  uint64_t t;
   memcpy(&t, p, sizeof t);
   return t;
 }
 
-inline void UnalignedStore64(void *p, uint64 v) { memcpy(p, &v, sizeof v); }
+inline void UnalignedStore64(void *p, uint64_t v) { memcpy(p, &v, sizeof v); }
 
 }  // namespace base_internal
 }  // namespace absl
@@ -286,8 +286,8 @@ inline uint32_t UnalignedLoad32(const vo
   return t;
 }
 
-inline uint64 UnalignedLoad64(const void *p) {
-  uint64 t;
+inline uint64_t UnalignedLoad64(const void *p) {
+  uint64_t t;
   memcpy(&t, p, sizeof t);
   return t;
 }
@@ -296,7 +296,7 @@ inline void UnalignedStore16(void *p, ui
 
 inline void UnalignedStore32(void *p, uint32_t v) { memcpy(p, &v, sizeof v); }
 
-inline void UnalignedStore64(void *p, uint64 v) { memcpy(p, &v, sizeof v); }
+inline void UnalignedStore64(void *p, uint64_t v) { memcpy(p, &v, sizeof v); }
 
 }  // namespace base_internal
 }  // namespace absl
diff -uprN a/src/s2/util/coding/coder.h b/src/s2/util/coding/coder.h
--- a/src/s2/util/coding/coder.h	2021-09-28 17:39:01.762719508 +0800
+++ b/src/s2/util/coding/coder.h	2021-09-28 17:44:11.903700328 +0800
@@ -155,7 +155,7 @@ class Encoder {
 class Decoder {
  public:
   // Empty constructor to create uninitialized decoder
-  inline Decoder() { }
+  inline Decoder() = default;
 
   // NOTE: for efficiency reasons, this is not virtual.  so don't add
   // any members that really need to be destructed, and be careful about
@@ -461,7 +461,7 @@ inline void DecoderExtensions::FillArray
                 "Decoder must be trivially copy-assignable");
   static_assert(absl::is_trivially_destructible<Decoder>::value,
                 "Decoder must be trivially destructible");
-  std::memset(array, 0, num_decoders * sizeof(Decoder));
+  std::memset(static_cast<void*>(array), 0, num_decoders * sizeof(Decoder));
 }
 
 inline void Encoder::put8(unsigned char v) {
