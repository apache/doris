--- lds-gen.py
+++ lds-gen.py
@@ -58,7 +58,7 @@ if __name__ == '__main__':
 
     # Special symbols not covered by above matches or not exposed in
     # the public header files.
-    funcs.append('rd_ut_coverage_check')
+    # funcs.append('rd_ut_coverage_check')
 
     print('# Automatically generated by lds-gen.py - DO NOT EDIT')
     print('{\n global:')
--- mklove/modules/configure.base
+++ mklove/modules/configure.base
@@ -1741,7 +1741,7 @@ function mkl_pkg_config_check {
     mkl_check_begin "$cname" "$2" "no-cache" "$1 (by pkg-config)" && return $?
 
     local cflags=
-    local cmd="${PKG_CONFIG} --short-errors --cflags $libname"
+    local cmd="${PKG_CONFIG} --static --short-errors --cflags $libname"
     mkl_dbg "pkg-config check $libname for CFLAGS ($2): $cmd"
 
     cflags=$($cmd 2>&1)
@@ -1764,11 +1764,11 @@ $cflags"
     fi
 
     local libs=
-    cmd="${PKG_CONFIG} --short-errors --libs $libname"
+    cmd="${PKG_CONFIG} --static --short-errors --libs $libname"
     mkl_dbg "pkg-config check $libname for LIBS ($2): $cmd"
     libs=$($cmd 2>&1)
     if [[ $? != 0 ]]; then
-        mkl_dbg "${PKG_CONFIG} --libs $libname failed: $libs"
+        mkl_dbg "${PKG_CONFIG} --static --libs $libname failed: $libs"
         # Clear define name ($2): caller may have additional checks
         mkl_check_failed "$cname" "" "$3" "pkg-config --libs failed"
         return 1
--- src/rdkafka.c
+++ src/rdkafka.c
@@ -3510,6 +3510,7 @@ rd_kafka_resp_err_t rd_kafka_query_watermark_offsets(rd_kafka_t *rk,
         struct rd_kafka_partition_leader *leader;
         rd_list_t leaders;
         rd_kafka_resp_err_t err;
+        int tmout;
 
         partitions = rd_kafka_topic_partition_list_new(1);
         rktpar =
@@ -3556,11 +3557,15 @@ rd_kafka_resp_err_t rd_kafka_query_watermark_offsets(rd_kafka_t *rk,
         rd_list_destroy(&leaders);
 
         /* Wait for reply (or timeout) */
-        while (state.err == RD_KAFKA_RESP_ERR__IN_PROGRESS &&
-               rd_kafka_q_serve(rkq, 100, 0, RD_KAFKA_Q_CB_CALLBACK,
-                                rd_kafka_poll_cb,
-                                NULL) != RD_KAFKA_OP_RES_YIELD)
-                ;
+        while (state.err == RD_KAFKA_RESP_ERR__IN_PROGRESS) {
+                tmout = rd_timeout_remains(ts_end);
+                if (rd_timeout_expired(tmout)) {
+                        state.err = RD_KAFKA_RESP_ERR__TIMED_OUT;
+                        break;
+                }
+                rd_kafka_q_serve(rkq, tmout, 0, RD_KAFKA_Q_CB_CALLBACK,
+                                 rd_kafka_poll_cb, NULL);
+        }
 
         rd_kafka_q_destroy_owner(rkq);
 
--- src/rdkafka_broker.c
+++ src/rdkafka_broker.c
@@ -5461,7 +5461,9 @@ static int rd_kafka_broker_thread_main(void *arg) {
  */
 void rd_kafka_broker_destroy_final(rd_kafka_broker_t *rkb) {
 
-        rd_assert(thrd_is_current(rkb->rkb_thread));
+        // To avoid the error describe in https://github.com/edenhill/librdkafka/issues/3608
+        // comment this line to fix it temporarily.
+        // rd_assert(thrd_is_current(rkb->rkb_thread));
         rd_assert(TAILQ_EMPTY(&rkb->rkb_monitors));
         rd_assert(TAILQ_EMPTY(&rkb->rkb_outbufs.rkbq_bufs));
         rd_assert(TAILQ_EMPTY(&rkb->rkb_waitresps.rkbq_bufs));
