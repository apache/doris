--- lds-gen.py
+++ lds-gen.py
@@ -58,7 +58,7 @@ if __name__ == '__main__':
 
     # Special symbols not covered by above matches or not exposed in
     # the public header files.
-    funcs.append('rd_ut_coverage_check')
+    # funcs.append('rd_ut_coverage_check')
 
     print('# Automatically generated by lds-gen.py - DO NOT EDIT')
     print('{\n global:')
--- mklove/modules/configure.base
+++ mklove/modules/configure.base
@@ -1741,7 +1741,7 @@ function mkl_pkg_config_check {
     mkl_check_begin "$cname" "$2" "no-cache" "$1 (by pkg-config)" && return $?
 
     local cflags=
-    local cmd="${PKG_CONFIG} --short-errors --cflags $libname"
+    local cmd="${PKG_CONFIG} --static --short-errors --cflags $libname"
     mkl_dbg "pkg-config check $libname for CFLAGS ($2): $cmd"
 
     cflags=$($cmd 2>&1)
@@ -1764,11 +1764,11 @@ $cflags"
     fi
 
     local libs=
-    cmd="${PKG_CONFIG} --short-errors --libs $libname"
+    cmd="${PKG_CONFIG} --static --short-errors --libs $libname"
     mkl_dbg "pkg-config check $libname for LIBS ($2): $cmd"
     libs=$($cmd 2>&1)
     if [[ $? != 0 ]]; then
-        mkl_dbg "${PKG_CONFIG} --libs $libname failed: $libs"
+        mkl_dbg "${PKG_CONFIG} --static --libs $libname failed: $libs"
         # Clear define name ($2): caller may have additional checks
         mkl_check_failed "$cname" "" "$3" "pkg-config --libs failed"
         return 1
--- src/rdkafka.c
+++ src/rdkafka.c
@@ -3510,6 +3510,7 @@ rd_kafka_resp_err_t rd_kafka_query_watermark_offsets(rd_kafka_t *rk,
         struct rd_kafka_partition_leader *leader;
         rd_list_t leaders;
         rd_kafka_resp_err_t err;
+        int tmout;
 
         partitions = rd_kafka_topic_partition_list_new(1);
         rktpar =
@@ -3556,11 +3557,15 @@ rd_kafka_resp_err_t rd_kafka_query_watermark_offsets(rd_kafka_t *rk,
         rd_list_destroy(&leaders);
 
         /* Wait for reply (or timeout) */
-        while (state.err == RD_KAFKA_RESP_ERR__IN_PROGRESS &&
-               rd_kafka_q_serve(rkq, 100, 0, RD_KAFKA_Q_CB_CALLBACK,
-                                rd_kafka_poll_cb,
-                                NULL) != RD_KAFKA_OP_RES_YIELD)
-                ;
+        while (state.err == RD_KAFKA_RESP_ERR__IN_PROGRESS) {
+                tmout = rd_timeout_remains(ts_end);
+                if (rd_timeout_expired(tmout)) {
+                        state.err = RD_KAFKA_RESP_ERR__TIMED_OUT;
+                        break;
+                }
+                rd_kafka_q_serve(rkq, tmout, 0, RD_KAFKA_Q_CB_CALLBACK,
+                                 rd_kafka_poll_cb, NULL);
+        }
 
         rd_kafka_q_destroy_owner(rkq);
 
--- src/rdkafka_broker.c
+++ src/rdkafka_broker.c
@@ -3288,6 +3288,11 @@ rd_kafka_broker_op_serve(rd_kafka_broker_t *rkb, rd_kafka_op_t *rko) {
                                 : (topic_err
                                        ? topic_err
                                        : RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION));
+
+                        if (rkb->rkb_rk->rk_type == RD_KAFKA_CONSUMER) {
+                                rd_kafka_toppar_purge_internal_fetch_queue_maybe(
+                                    rktp);
+                        }
                 }
 
                 rd_kafka_toppar_unlock(rktp);
@@ -5461,7 +5466,9 @@ static int rd_kafka_broker_thread_main(void *arg) {
  */
 void rd_kafka_broker_destroy_final(rd_kafka_broker_t *rkb) {
 
-        rd_assert(thrd_is_current(rkb->rkb_thread));
+        // To avoid the error describe in https://github.com/edenhill/librdkafka/issues/3608
+        // comment this line to fix it temporarily.
+        // rd_assert(thrd_is_current(rkb->rkb_thread));
         rd_assert(TAILQ_EMPTY(&rkb->rkb_monitors));
         rd_assert(TAILQ_EMPTY(&rkb->rkb_outbufs.rkbq_bufs));
         rd_assert(TAILQ_EMPTY(&rkb->rkb_waitresps.rkbq_bufs));
--- src/rdkafka_cgrp.c
+++ src/rdkafka_cgrp.c
@@ -2734,6 +2734,9 @@ static void rd_kafka_cgrp_partition_del(rd_kafka_cgrp_t *rkcg,
         rd_kafka_toppar_lock(rktp);
         rd_assert(rktp->rktp_flags & RD_KAFKA_TOPPAR_F_ON_CGRP);
         rktp->rktp_flags &= ~RD_KAFKA_TOPPAR_F_ON_CGRP;
+
+        rd_kafka_toppar_purge_internal_fetch_queue_maybe(rktp);
+
         rd_kafka_toppar_unlock(rktp);
 
         rd_list_remove(&rkcg->rkcg_toppars, rktp);
--- src/rdkafka_partition.c
+++ src/rdkafka_partition.c
@@ -959,7 +959,71 @@ void rd_kafka_toppar_insert_msgq(rd_kafka_toppar_t *rktp,
         rd_kafka_toppar_unlock(rktp);
 }
 
+/**
+ * @brief Purge internal fetch queue if toppar is stopped
+ * (RD_KAFKA_TOPPAR_FETCH_STOPPED) and removed from the cluster
+ * (RD_KAFKA_TOPPAR_F_REMOVE). Will be called from different places as it's
+ * removed starting from a metadata response and stopped from a rebalance or a
+ * consumer close.
+ *
+ * @remark Avoids circular dependencies in from `rktp_fetchq` ops to the same
+ * toppar that stop destroying a consumer.
+ *
+ * @locks rd_kafka_toppar_lock() MUST be held
+ */
+void rd_kafka_toppar_purge_internal_fetch_queue_maybe(rd_kafka_toppar_t *rktp) {
+        rd_kafka_q_t *rkq;
+        rkq = rktp->rktp_fetchq;
+        mtx_lock(&rkq->rkq_lock);
+        if (rktp->rktp_flags & RD_KAFKA_TOPPAR_F_REMOVE &&
+            !rktp->rktp_fetchq->rkq_fwdq) {
+                rd_kafka_op_t *rko;
+                int cnt = 0, barrier_cnt = 0, message_cnt = 0, other_cnt = 0;
+
+                /* Partition is being removed from the cluster and it's stopped,
+                 * so rktp->rktp_fetchq->rkq_fwdq is NULL.
+                 * Purge remaining operations in rktp->rktp_fetchq->rkq_q,
+                 * while holding lock, to avoid circular references */
+                rko = TAILQ_FIRST(&rkq->rkq_q);
+                while (rko) {
+                        if (rko->rko_type != RD_KAFKA_OP_BARRIER &&
+                            rko->rko_type != RD_KAFKA_OP_FETCH) {
+                                rd_kafka_log(
+                                    rktp->rktp_rkt->rkt_rk, LOG_WARNING,
+                                    "PARTDEL",
+                                    "Purging toppar fetch queue buffer op"
+                                    "with unexpected type: %s",
+                                    rd_kafka_op2str(rko->rko_type));
+                        }
+
+                        if (rko->rko_type == RD_KAFKA_OP_BARRIER)
+                                barrier_cnt++;
+                        else if (rko->rko_type == RD_KAFKA_OP_FETCH)
+                                message_cnt++;
+                        else
+                                other_cnt++;
 
+                        rko = TAILQ_NEXT(rko, rko_link);
+                        cnt++;
+                }
+
+                if (cnt) {
+                        rd_kafka_dbg(rktp->rktp_rkt->rkt_rk, CGRP, "PARTDEL",
+                                     "Purge toppar fetch queue buffer "
+                                     "containing %d op(s) "
+                                     "(%d barrier(s), %d message(s), %d other)"
+                                     " to avoid "
+                                     "circular references",
+                                     cnt, barrier_cnt, message_cnt, other_cnt);
+                        rd_kafka_q_purge0(rktp->rktp_fetchq, rd_false);
+                } else {
+                        rd_kafka_dbg(rktp->rktp_rkt->rkt_rk, CGRP, "PARTDEL",
+                                     "Not purging toppar fetch queue buffer."
+                                     " No ops present in the buffer.");
+                }
+        }
+        mtx_unlock(&rkq->rkq_lock);
+}
 
 /**
  * Helper method for purging queues when removing a toppar.
--- src/rdkafka_partition.h
+++ src/rdkafka_partition.h
@@ -541,6 +541,8 @@ void rd_kafka_toppar_offset_request(rd_kafka_toppar_t *rktp,
                                     int64_t query_offset,
                                     int backoff_ms);
 
+void rd_kafka_toppar_purge_internal_fetch_queue_maybe(rd_kafka_toppar_t *rktp);
+
 int rd_kafka_toppar_purge_queues(rd_kafka_toppar_t *rktp,
                                  int purge_flags,
                                  rd_bool_t include_xmit_msgq);
