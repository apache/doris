-- This file is automatically generated. You should know what you did if you want to edit this
-- !tokenize_standard --
[{\n        "token": "apache"\n    }, {\n        "token": "doris"\n    }, {\n        "token": "fast"\n    }, {\n        "token": "mpp"\n    }, {\n        "token": "database"\n    }]

-- !tokenize_unicode --
[{\n        "token": "hello"\n    }, {\n        "token": "world"\n    }, {\n        "token": "你"\n    }, {\n        "token": "好"\n    }, {\n        "token": "世"\n    }, {\n        "token": "界"\n    }]

-- !tokenize_basic --
[{\n        "token": "get"\n    }, {\n        "token": "images"\n    }, {\n        "token": "test"\n    }, {\n        "token": "jpg"\n    }, {\n        "token": "http"\n    }, {\n        "token": "1"\n    }, {\n        "token": "0"\n    }]

-- !tokenize_icu --
[{\n        "token": "让"\n    }, {\n        "token": "我们"\n    }, {\n        "token": "说"\n    }, {\n        "token": "hello"\n    }, {\n        "token": "そして"\n    }, {\n        "token": "世界"\n    }, {\n        "token": "と"\n    }, {\n        "token": "つ"\n    }, {\n        "token": "な"\n    }, {\n        "token": "が"\n    }, {\n        "token": "ろう"\n    }]

-- !tokenize_chinese_standard --
[{\n        "token": "apache"\n    }, {\n        "token": "doris"\n    }, {\n        "token": "是"\n    }, {\n        "token": "一"\n    }, {\n        "token": "个"\n    }, {\n        "token": "现"\n    }, {\n        "token": "代"\n    }, {\n        "token": "化"\n    }, {\n        "token": "的"\n    }, {\n        "token": "mpp"\n    }, {\n        "token": "数"\n    }, {\n        "token": "据"\n    }, {\n        "token": "库"\n    }]

-- !tokenize_chinese_basic --
[{\n        "token": "apache"\n    }, {\n        "token": "doris"\n    }, {\n        "token": "是"\n    }, {\n        "token": "一"\n    }, {\n        "token": "个"\n    }, {\n        "token": "现"\n    }, {\n        "token": "代"\n    }, {\n        "token": "化"\n    }, {\n        "token": "的"\n    }, {\n        "token": "mpp"\n    }, {\n        "token": "数"\n    }, {\n        "token": "据"\n    }, {\n        "token": "库"\n    }]

-- !tokenize_chinese_icu --
[{\n        "token": "apache"\n    }, {\n        "token": "doris"\n    }, {\n        "token": "是"\n    }, {\n        "token": "一个"\n    }, {\n        "token": "现代"\n    }, {\n        "token": "化"\n    }, {\n        "token": "的"\n    }, {\n        "token": "mpp"\n    }, {\n        "token": "数据"\n    }, {\n        "token": "库"\n    }]

-- !tokenize_special_standard --
[{\n        "token": "test"\n    }, {\n        "token": "example.com"\n    }, {\n        "token": "user_name"\n    }, {\n        "token": "123"\n    }, {\n        "token": "456"\n    }]

-- !tokenize_empty --


-- !tokenize_mixed --
[{\n        "token": "中文"\n    }, {\n        "token": "english"\n    }, {\n        "token": "日本語"\n    }, {\n        "token": "한국어"\n    }]

-- !sql_basic_match_logo --
1	GET /images/logo.png HTTP/1.0

-- !sql_basic_match_images --
1	GET /images/logo.png HTTP/1.0

-- !sql_basic_match_api --
2	POST /api/v1/users HTTP/1.1

-- !sql_basic_match_logo --
1	GET /images/logo.png HTTP/1.0

-- !sql_basic_match_images --
1	GET /images/logo.png HTTP/1.0

-- !sql_basic_match_api --
2	POST /api/v1/users HTTP/1.1

