---
{
    "title": "Partial Update",
    "language": "en"
}
---

<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

# Partial Update

Doris's default data write semantics are whole-row Upsert. Before version 2.0, if users wanted to update certain columns of some rows, they could only use the `UPDATE` command. However, due to the granularity of locks in read-write transactions, the `UPDATE` command is not suitable for high-frequency data write scenarios. Therefore, in version 2.0, we introduced support for partial column updates in the Unique Key model.

> Note:
>
> 1. Partial update are only supported in the Unique Key Merge-on-Write implementation in version 2.0.0.
> 2. Version 2.0.2 introduces support for performing partial column updates using `INSERT INTO`.
> 3. Version 2.1.0 will bring support for partial column updates in the Unique Key model's Merge-on-Read implementation.
> 4. Version 2.1.0 will offer more flexible column updates, as described in the "Usage Limitations" section below.

## Applicable scenarios

+ Real-time dynamic column updates. Where certain field values in the table need to be updated in real-time at high frequencies. For example, in a user label table generated by T+1, some fields containing information about the latest user behaviors need to be updated in real-time for real-time analysis and decision-making in advertising/recommendation systems.
+ Combining multiple source tables into one large wide table.
+ Data correction.

## Fundamentals

### Merge-on-Write Implementation

Users write data for certain columns into Doris's Memtable through the regular load methods. At this point, the Memtable does not contain complete rows of data. When flushing the Memtable, Doris searches for historical data, fills in the entire row, then writes it to the data file, and marks the data rows with the same key in the historical data file as deleted.

In the case of concurrent loads, Doris uses the MVCC mechanism to ensure data correctness. If two batches of loaded data update different columns with the same key, the load task with the higher system version will recomplete the data rows with the same key written by the lower version load task after the lower version load task succeeds.

### Merge-on-Read Implementation

No extra-processing is performed on the data during the write process. Data aggregation from different data files is done during data retrieval using the REPLACE_IF_NOT_NULL aggregation function.

## Concurrent Writes and Data Visibility

Partial column updates support high-frequency concurrent writes, and once the write is successful, the data becomes visible. The system automatically ensures the correctness of concurrent writes through the MVCC mechanism.

## Performance

Usage Recommendations:

1. For users with high write performance requirements and low query performance requirements, it is recommended to use the Merge-on-Read implementation.
2. For users with high query performance requirements and lower write performance requirements (e.g., data writes and updates are mainly completed during off-peak hours in the early morning), or for users with low write frequency, it is recommended to use the Merge-on-Write implementation.

### Merge-on-Write Implementation

Since the Merge-on-Write implementation requires filling in entire rows of data during data writes to ensure optimal query performance, performing partial column updates using the Merge-on-Write implementation may lead to noticeable load performance degradation.

Write Performance Optimization Recommendations:

1. Use SSDs equipped with NVMe or high-speed SSD cloud disks. Because reading historical data in large quantities occurs when filling in row data, might results in higher read IOPS and read throughput.
2. Enabling row storage can significantly reduce the IOPS generated when filling in row data, leading to a noticeable improvement in load performance. Users can enable row storage when creating tables using the following property:

```
"store_row_column" = "true"
```

### Merge-on-Read Implementation

The Merge-on-Read implementation does not perform any additional processing during the write process, so write performance is not affected and is the same as regular data load jobs. However, the cost of aggregation during queries is relatively high, with typical aggregate query performance being 5-10 times lower compared to the Merge-on-Write implementation.

 ## Usage Instructions

Due to significant differences in implementation, Merge-on-Write and Merge-on-Read implementations cannot be completely unified in terms of usage. Users should choose different implementations and usage methods based on their own requirements.

> Note: This document currently only provides a usage example for partial column updates with Merge-on-Write. After version 2.1.0 is officially released, we will update the usage examples for Merge-on-Read.

### Merge-on-Write Implementation

#### StreamLoad/BrokerLoad/RoutineLoad

If you are using StreamLoad/BrokerLoad/RoutineLoad, add the following header when loading:

```
partial_columns:true
```

Also, specify the columns to be loaded in the `columns` header (it must include all key columns, or else updates cannot be performed).

#### INSERT INTO

In all data models, by default, when you use `INSERT INTO` with a given set of columns, the default behavior is to insert the entire row. To enable partial column updates in the Merge-on-Write implementation, you need to set the following session variable:

```
set enable_unique_key_partial_update=true
```

## Usage Example

Suppose there is an order table `order_tbl` in Doris, where the order ID is the Key column, and the order status and order amount are Value columns. The data status is as follows:

| Order ID | Order Amount | Order Status    |
| -------- | ------------ | --------------- |
| 1        | 100          | Pending Payment |

```sql
+----------+--------------+-----------------+
| order_id | order_amount | order_status    |
+----------+--------------+-----------------+
| 1        | 100          | Pending Payment |
+----------+--------------+-----------------+
1 row in set (0.01 sec)
```

Now, when a user clicks to make a payment, he needs to change the order status of the order with Order ID '1' to 'Pending Delivery'.

If you are using StreamLoad, you can perform the update as follows:

```sql
$ cat update.csv
1,Pending Delivery

$ curl  --location-trusted -u root: -H "partial_columns:true" -H "column_separator:," -H "columns:order_id,order_status" -T /tmp/update.csv http://127.0.0.1:48037/api/db1/order_tbl/_stream_load
```

If you are using `INSERT INTO`, you can perform the update as follows:

```sql
set enable_unique_key_partial_update=true;
INSERT INTO order_tbl (order_id, order_status) values (1,'Pending Delivery');
```

The updated result is as follows:

```sql
+----------+--------------+------------------+
| order_id | order_amount | order_status     |
+----------+--------------+------------------+
| 1        | 100          | Pending Delivery |
+----------+--------------+------------------+
1 row in set (0.01 sec)
```

## Usage Limitations

In version 2.0, all rows in the same batch of data write tasks (whether load tasks or `INSERT INTO`) can only update the same columns. If you need to update different columns of data, you will need to write them in separate batches.

In version 2.1, we will support more flexible column updates, allowing users to update different columns for each row within the same batch load.

## More Help

For more information about the Merge-on-Read and Merge-on-Write implementations of the Unique Key, please refer to the introduction in the [Data Model](../../data-table/data-model.md).
