// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

package org.apache.doris.nereids.trees.plans;

import org.apache.doris.analysis.AggregateInfo;
import org.apache.doris.analysis.Expr;
import org.apache.doris.analysis.FunctionCallExpr;
import org.apache.doris.analysis.SlotDescriptor;
import org.apache.doris.analysis.SortInfo;
import org.apache.doris.analysis.TupleDescriptor;
import org.apache.doris.catalog.OlapTable;
import org.apache.doris.catalog.Table;
import org.apache.doris.nereids.operators.plans.JoinType;
import org.apache.doris.nereids.operators.plans.physical.PhysicalAggregation;
import org.apache.doris.nereids.operators.plans.physical.PhysicalFilter;
import org.apache.doris.nereids.operators.plans.physical.PhysicalHashJoin;
import org.apache.doris.nereids.operators.plans.physical.PhysicalOlapScan;
import org.apache.doris.nereids.operators.plans.physical.PhysicalOperator;
import org.apache.doris.nereids.operators.plans.physical.PhysicalProject;
import org.apache.doris.nereids.operators.plans.physical.PhysicalSort;
import org.apache.doris.nereids.properties.OrderKey;
import org.apache.doris.nereids.trees.expressions.Expression;
import org.apache.doris.nereids.trees.expressions.ExpressionConverter;
import org.apache.doris.nereids.trees.expressions.Slot;
import org.apache.doris.nereids.trees.expressions.SlotReference;
import org.apache.doris.nereids.trees.plans.physical.PhysicalBinaryPlan;
import org.apache.doris.nereids.trees.plans.physical.PhysicalLeafPlan;
import org.apache.doris.nereids.trees.plans.physical.PhysicalPlan;
import org.apache.doris.nereids.trees.plans.physical.PhysicalUnaryPlan;
import org.apache.doris.nereids.util.Utils;
import org.apache.doris.planner.AggregationNode;
import org.apache.doris.planner.CrossJoinNode;
import org.apache.doris.planner.DataPartition;
import org.apache.doris.planner.ExchangeNode;
import org.apache.doris.planner.HashJoinNode;
import org.apache.doris.planner.OlapScanNode;
import org.apache.doris.planner.PlanFragment;
import org.apache.doris.planner.PlanNode;
import org.apache.doris.planner.SortNode;

import com.google.common.base.Preconditions;
import com.google.common.collect.Lists;

import java.util.ArrayList;
import java.util.List;
import java.util.stream.Collectors;

/**
 * Used to translate to physical plan generated by new optimizer to the plan fragments.
 */
@SuppressWarnings("rawtypes")
public class PhysicalPlanTranslator extends PlanOperatorVisitor<PlanFragment, PlanContext> {

    public void translatePlan(PhysicalPlan physicalPlan, PlanContext context) {
        visit(physicalPlan, context);
    }

    @Override
    public PlanFragment visit(Plan plan, PlanContext context) {
        PhysicalOperator operator = (PhysicalOperator) plan.getOperator();
        return operator.accept(this, plan, context);
    }

    /**
     * Translate in following steps:
     *  1.
     *
     */
    @Override
    public PlanFragment visitPhysicalAggregation(
            PhysicalUnaryPlan<PhysicalAggregation, Plan> agg, PlanContext context) {

        PlanFragment inputPlanFragment = visit(agg.child(0), context);

        AggregationNode aggregationNode = null;
        List<Slot> slotList = agg.getOutput();
        TupleDescriptor outputTupleDesc = generateTupleDesc(slotList, context, null);
        PhysicalAggregation physicalAggregation = agg.getOperator();
        AggregateInfo.AggPhase phase = physicalAggregation.getAggPhase().toExec();

        List<Expression> groupByExpressionList = physicalAggregation.getGroupByExprList();
        ArrayList<Expr> execGroupingExpressions = groupByExpressionList.stream()
                .map(e -> ExpressionConverter.converter.convert(e)).collect(Collectors.toCollection(ArrayList::new));

        List<Expression> aggExpressionList = physicalAggregation.getAggExprList();
        // TODO: agg function could be other expr type either
        ArrayList<FunctionCallExpr> execAggExpressions = aggExpressionList.stream()
                .map(e -> (FunctionCallExpr) ExpressionConverter.converter.convert(e))
                .collect(Collectors.toCollection(ArrayList::new));

        List<Expression> partitionExpressionList = physicalAggregation.getPartitionExprList();
        List<Expr> execPartitionExpressions = partitionExpressionList.stream()
                .map(e -> (FunctionCallExpr) ExpressionConverter.converter.convert(e)).collect(Collectors.toList());
        // todo: support DISTINCT
        AggregateInfo aggInfo = null;
        switch (phase) {
            case FIRST:
                aggInfo = AggregateInfo.create(execGroupingExpressions, execAggExpressions, outputTupleDesc,
                        outputTupleDesc, AggregateInfo.AggPhase.FIRST);
                aggregationNode = new AggregationNode(context.nextNodeId(), inputPlanFragment.getPlanRoot(), aggInfo);
                aggregationNode.unsetNeedsFinalize();
                aggregationNode.setUseStreamingPreagg(physicalAggregation.isUsingStream());
                aggregationNode.setIntermediateTuple();
                if (!partitionExpressionList.isEmpty()) {
                    inputPlanFragment.setOutputPartition(DataPartition.hashPartitioned(execPartitionExpressions));
                }
                break;
            case FIRST_MERGE:
                aggInfo = AggregateInfo.create(execGroupingExpressions, execAggExpressions, outputTupleDesc,
                        outputTupleDesc, AggregateInfo.AggPhase.FIRST_MERGE);
                aggregationNode = new AggregationNode(context.nextNodeId(), inputPlanFragment.getPlanRoot(), aggInfo);
                break;
            default:
                throw new RuntimeException("Unsupported yet");
        }
        inputPlanFragment.setPlanRoot(aggregationNode);
        return inputPlanFragment;
    }

    @Override
    public PlanFragment visitPhysicalOlapScan(
            PhysicalLeafPlan<PhysicalOlapScan> olapScan, PlanContext context) {
        // Create OlapScanNode
        List<Slot> slotList = olapScan.getOutput();
        PhysicalOlapScan physicalOlapScan = olapScan.getOperator();
        OlapTable olapTable = physicalOlapScan.getTable();
        TupleDescriptor tupleDescriptor = generateTupleDesc(slotList, context, olapTable);
        OlapScanNode olapScanNode = new OlapScanNode(context.nextNodeId(), tupleDescriptor, olapTable.getName());
        // Create PlanFragment
        PlanFragment planFragment = new PlanFragment(context.nextFragmentId(), olapScanNode, DataPartition.RANDOM);
        context.addPlanFragment(planFragment);
        return planFragment;
    }

    @Override
    public PlanFragment visitPhysicalSort(PhysicalUnaryPlan<PhysicalSort, Plan> sort,
            PlanContext context) {
        PlanFragment childFragment = visit(sort.child(0), context);
        PhysicalSort physicalSort = sort.getOperator();
        if (!childFragment.isPartitioned()) {
            return childFragment;
        }
        long limit = physicalSort.getLimit();

        List<Expr> execOrderingExprList = Lists.newArrayList();
        List<Boolean> ascOrderList = Lists.newArrayList();
        List<Boolean> nullsFirstParamList = Lists.newArrayList();

        List<OrderKey> orderKeyList = physicalSort.getOrderList();
        orderKeyList.forEach(k -> {
            execOrderingExprList.add(ExpressionConverter.converter.convert(k.getExpr()));
            ascOrderList.add(k.isAsc());
            nullsFirstParamList.add(k.isNullFirst());
        });

        List<Slot> outputList = sort.getOutput();
        TupleDescriptor tupleDesc = generateTupleDesc(outputList, context, null);
        SortInfo sortInfo = new SortInfo(execOrderingExprList, ascOrderList, nullsFirstParamList, tupleDesc);

        PlanNode childNode = childFragment.getPlanRoot();
        SortNode sortNode = new SortNode(context.nextNodeId(), childNode, sortInfo, physicalSort.isUseTopN(),
                physicalSort.hasLimit(), physicalSort.getOffset());

        PlanFragment mergeFragment = createParentFragment(childFragment, DataPartition.UNPARTITIONED, context);
        ExchangeNode exchNode = (ExchangeNode) mergeFragment.getPlanRoot();
        exchNode.unsetLimit();
        if (physicalSort.hasLimit()) {
            exchNode.setLimit(limit);
        }
        long offset = physicalSort.getOffset();
        exchNode.setMergeInfo(sortNode.getSortInfo(), offset);

        // Child nodes should not process the offset. If there is a limit,
        // the child nodes need only return (offset + limit) rows.
        SortNode childSortNode = (SortNode) childFragment.getPlanRoot();
        Preconditions.checkState(sortNode == childSortNode);
        if (sortNode.hasLimit()) {
            childSortNode.unsetLimit();
            childSortNode.setLimit(limit + offset);
        }
        childSortNode.setOffset(0);
        return mergeFragment;
    }

    // TODO: support broadcast join / co-locate / bucket shuffle join later
    @Override
    public PlanFragment visitPhysicalHashJoin(
            PhysicalBinaryPlan<PhysicalHashJoin, Plan, Plan> hashJoin, PlanContext context) {
        PlanFragment leftFragment = visit(hashJoin.child(0), context);
        PlanFragment rightFragment = visit(hashJoin.child(0), context);
        PhysicalHashJoin physicalHashJoin = hashJoin.getOperator();
        Expression predicateExpr = physicalHashJoin.getCondition();
        List<Expression> eqExprList = Utils.getEqConjuncts(hashJoin.child(0).getOutput(),
                hashJoin.child(1).getOutput(), predicateExpr);
        JoinType joinType = physicalHashJoin.getJoinType();

        PlanNode leftFragmentPlanRoot = leftFragment.getPlanRoot();
        PlanNode rightFragmentPlanRoot = rightFragment.getPlanRoot();

        if (joinType.equals(JoinType.CROSS_JOIN)
                || physicalHashJoin.getJoinType().equals(JoinType.INNER_JOIN) && eqExprList.isEmpty()) {
            CrossJoinNode crossJoinNode = new CrossJoinNode(context.nextNodeId(), leftFragment.getPlanRoot(),
                    rightFragment.getPlanRoot(), null);
            crossJoinNode.setLimit(physicalHashJoin.getLimited());
            List<Expr> conjuncts = Utils.extractConjuncts(predicateExpr).stream()
                    .map(e -> ExpressionConverter.converter.convert(e))
                    .collect(Collectors.toCollection(ArrayList::new));
            crossJoinNode.addConjuncts(conjuncts);
            ExchangeNode exchangeNode = new ExchangeNode(context.nextNodeId(), rightFragment.getPlanRoot(), false);
            exchangeNode.setNumInstances(rightFragmentPlanRoot.getNumInstances());
            exchangeNode.setFragment(leftFragment);
            leftFragmentPlanRoot.setChild(1, exchangeNode);
            rightFragment.setDestination(exchangeNode);
            crossJoinNode.setChild(0, leftFragment.getPlanRoot());
            leftFragment.setPlanRoot(crossJoinNode);
            return leftFragment;
        }

        List<Expression> expressionList = Utils.extractConjuncts(predicateExpr);
        expressionList.removeAll(eqExprList);
        List<Expr> execOtherConjunctList = expressionList.stream().map(e -> ExpressionConverter.converter.convert(e))
                .collect(Collectors.toCollection(ArrayList::new));
        List<Expr> execEqConjunctList = eqExprList.stream().map(e -> ExpressionConverter.converter.convert(e))
                .collect(Collectors.toCollection(ArrayList::new));

        HashJoinNode hashJoinNode = new HashJoinNode(context.nextNodeId(), leftFragmentPlanRoot, rightFragmentPlanRoot,
                JoinType.toJoinOperator(physicalHashJoin.getJoinType()), execEqConjunctList, execOtherConjunctList);

        ExchangeNode leftExch = new ExchangeNode(context.nextNodeId(), leftFragmentPlanRoot, false);
        leftExch.setNumInstances(leftFragmentPlanRoot.getNumInstances());
        ExchangeNode rightExch = new ExchangeNode(context.nextNodeId(), leftFragmentPlanRoot, false);
        rightExch.setNumInstances(rightFragmentPlanRoot.getNumInstances());
        hashJoinNode.setChild(0, leftFragmentPlanRoot);
        hashJoinNode.setChild(1, leftFragmentPlanRoot);
        hashJoinNode.setDistributionMode(HashJoinNode.DistributionMode.PARTITIONED);
        hashJoinNode.setLimit(physicalHashJoin.getLimited());
        leftFragment.setDestination((ExchangeNode) rightFragment.getPlanRoot());
        rightFragment.setDestination((ExchangeNode) leftFragmentPlanRoot);
        return new PlanFragment(context.nextFragmentId(), hashJoinNode, leftFragment.getDataPartition());
    }

    @Override
    public PlanFragment visitPhysicalProject(
            PhysicalUnaryPlan<PhysicalProject, Plan> projectPlan, PlanContext context) {
        return visit(projectPlan.child(0), context);
    }

    @Override
    public PlanFragment visitPhysicalFilter(
            PhysicalUnaryPlan<PhysicalFilter, Plan> filterPlan, PlanContext context) {
        PlanFragment inputFragment = visit(filterPlan.child(0), context);
        PlanNode planNode = inputFragment.getPlanRoot();
        PhysicalFilter filter = filterPlan.getOperator();
        Expression expression = filter.getPredicates();
        List<Expression> expressionList = Utils.extractConjuncts(expression);
        expressionList.stream().map(ExpressionConverter.converter::convert).forEach(planNode::addConjunct);
        return inputFragment;
    }

    private TupleDescriptor generateTupleDesc(List<Slot> slotList, PlanContext context, Table table) {
        TupleDescriptor tupleDescriptor = context.generateTupleDesc();
        tupleDescriptor.setTable(table);
        for (Slot slot : slotList) {
            SlotReference slotReference = (SlotReference) slot;
            SlotDescriptor slotDescriptor = context.addSlotDesc(tupleDescriptor, slot.getId().asInt());
            slotDescriptor.setColumn(slotReference.getColumn());
            slotDescriptor.setType(slotReference.getDataType().toCatalogDataType());
            slotDescriptor.setIsMaterialized(true);
        }
        return tupleDescriptor;
    }

    private PlanFragment createParentFragment(PlanFragment childFragment, DataPartition parentPartition,
            PlanContext ctx) {
        ExchangeNode exchangeNode = new ExchangeNode(ctx.nextNodeId(), childFragment.getPlanRoot(), false);
        exchangeNode.setNumInstances(childFragment.getPlanRoot().getNumInstances());
        PlanFragment parentFragment = new PlanFragment(ctx.nextFragmentId(), exchangeNode, parentPartition);
        childFragment.setDestination(exchangeNode);
        childFragment.setOutputPartition(parentPartition);
        return parentFragment;
    }

    /**
     * Helper function to eliminate unnecessary checked exception caught requirement from the main logic of translator.
     *
     * @param f function which would invoke the logic of
     *        stale code from old optimizer that could throw
     *        a checked exception
     */
    public void exec(FuncWrapper f) {
        try {
            f.exec();
        } catch (Exception e) {
            throw new RuntimeException("Unexpected Exception: ", e);
        }
    }

    private interface FuncWrapper {
        void exec() throws Exception;
    }
}
