现状
1. 导入结束后不会更新产生的rowset meta到BE本地tablet meta
2. compaction结束后会将产生的rowset meta和最新的compaction cnt更新到BE tablet meta
可能的问题
- 由于导入后产生的rowset meta不会直接更新到be本地，每次有导入之后的第一次查询都会产生ms get_rowset rpc，会导致查询延迟增加
- be节点每次重启后，在这个节点上的tablet第一次活跃的时候都会有一次从ms拉取全量rowset meta的过程，可能对ms和fdb压力比较大？
- 总体上be到ms的get_rowset rpc比较多，可能对fdb压力大？
  - 不一定是问题，因为ms rpc高不一定表示读fdb kv多，一个get_rowset rpc进来如果calc_sync_versions算出来没有需要同步的rowset meta，除了所有rpc都会读的几个kv，不会读rowset meta KV
be上sync rowset的地方和流程
- 查询时FE会下发一个req version=A(partition version，可能来自ms或fe内存cache)，如果BE上对应的tablet本地的rowset meta的max version < A 则向MS发rpc get_rowset拉取增量rowset metameta
- 其他情况都是设置req version=max_version向ms发get_rowset rpc拉取rowset meta，这包括
  1. mow导入开始时
  2. Mow publish阶段计算delete bitmap时(be测判断version，compaction cnts没变化时会跳过)
  3. Compaction开始时
  4. Mow compaction计算delete bitmap时
  5. 一个后台线程周期性(10min)对超过30min没有sync rowset的tablet调用sync_rowset
MS get_rowset逻辑
请求中有be上该tablet当前的最大version和compaction cnts来表示一个rowset布局，通过和ms中的对比计算需要同步的rowse meta(calc_sync_versions)
目标
- 减少由于get_rowset导致的对fdb的读压力
- 减少由于拉取增量元数据导致的查询延迟
- 减少到MS的get_rowset rpc次数？
一些可能的优化
下面的优化都基于一个假设前提：一个tablet不会频繁在BE之间移动 
- 一般情况下是否成立? BE(频繁)重启下是否成立?
- 每个replica有primarybackends，挂掉超过fe conf rehash_tablet_after_be_dead_seconds(默认3600s)时间后改primarybackends元数据，读写默认走primarybackend，不可用时走secondarybackends
减少从ms拉取导入产生的rowset meta?
- 导入最终在MS提交事务的时候只修改了rowset meta中的start_version/end_version/visible_ts_ms字段
- BE在导入阶段将产生的rowset meta存放在内存中?/持久化?，导入结束后将需要更新的几个字段下发到BE上让BE原地更新rowset meta并放入tablet meta中(只通知，best effort，不用保证成功)
  - 增加一个类似CloudTxnDeleteBitmapCache的东西在内存中存导入产生的rowset meta，后台线程按照事务超时时间清理
  - 列更新publish阶段会修改rowset meta需要同步修改
  - 对于在 fe ->ms commit_txn的事务，fe直接通知对应的be
  - 对于在 be -> ms commit_txn的事务，广播BE通知?/转发给FE再通知对应BE？
  - fe增加一个后台线程?/一个线程池? 负责广播通知be，异步通知be，不阻塞commit txn流程
    - 通知到达be可能乱序，需要特殊处理
      - 只接受version == max_version + 1的通知？一旦发生一次乱序，后面的在内存中的rowset meta都会浪费
      - be收到通知后标记一下内存cache rowset的状态为publish，每次be收到通知时，尽可能地将版本连续的已经publish的rowset加入到tablet meta中
- 效果：查询时大概率不用sync_rowset了，减少ms get_rowset rpc次数和读fdb次数
- 还要考虑delete bitmap
减少BE重启后大量get_rowset对MS和fdb的压力?
- 在BE上 每次rowset布局发生变化?/定期? 将tablet的rowset meta持久化到本地rocksdb中，重启BE后，某个tablet第一次进入cloudtabletcache中时：
  - 可能这个tablet已经在别的be上发生过导入/查询了，先尝试从其他BE内存中获取rowset meta(复用-230的代码?)
    - 一个be挂掉后，读写切到secondaryBE上，此时在secondaryBE会全量从ms拉rowset meta
    - 在rehash_tablet_after_be_dead_seconds时间内primarybe重启，读写切回primarybe，此时primarybe可以在刚才的secondaryBE内存中拉到较新的rowset meta
    - Cloud tablet被正常rebalance到其他be上的情况，可以从srcBE内存拉到较新的rowset meta
  - 然后尝试从本地rocksdb(以及其他所有be的rocksdb中?)获取rowset meta，
    - 所有be同时停止重启的情况，可以从rocksdb中恢复出来最新rowset meta
  - 之后再向ms get_rowset
- 持久化的rowset meta的生命周期？过期清理时间？
- 效果：可以减少读取fdb KV的量
去掉cloud mow导入开始时的sync_rowset?
- Cloud mow为了尽可能减少在publish阶段对增量rowset计算delete bitmap(publish阶段在锁里，延迟会传播到所有其他排队的导入上)，会在导入开始的时候sync_rowset
- 在“一个tablet大多数时候是保持在一个be上”这个假设成立的情况下，以及上述导入后通知be原地更新rowset meta的机制下，可能可以去掉这次sync_rowset
- Bad case：如果一个tablet频繁在be之前移动，会在publish阶段对大量rowset计算delete bitmap，性能会很费















